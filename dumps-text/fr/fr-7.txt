   #alternate

   Afis Science - Association franÃ§aise pour l'information scientifique
   Association FranÃ§aise pour lâ€™Information Scientifique

     * Lâ€™association
          + Quâ€™est-ce que lâ€™AFIS ?
          + CommuniquÃ©s
          + Agenda
          + Liens internationaux
          + AdhÃ©rer
          + Contact
     * ARTICLES
          + Ã‰ditoriaux
          + Notes de lecture
          + Science et esprit critique
          + IntÃ©gritÃ© scientifique
          + Sornettes sur Internet
          + Un monde fou, fou, fou
          + Regards sur la science
          + Articles par thÃ¨me
     * REVUE
          + Le dernier numÃ©ro
          + Tous les numÃ©ros
          + S'abonner
     * BOUTIQUE
     * LIBRAIRIE
     * VIDÃ‰OS
     * Recherche

   Afis facebook Afis twitter Afis Youtube Afis Android Afis ios Afis RSS
   Mon compte

   Accueil / IA gÃ©nÃ©ratives : un risque accru de dÃ©sinformation ?

IA gÃ©nÃ©ratives : un risque accru de dÃ©sinformation ?

   PubliÃ© en ligne le 29 septembre 2023 - Intelligence Artificielle -
   IA gÃ©nÃ©ratives : un risque accru de dÃ©sinformation ?

   Les systÃ¨mes dâ€™intelligence artificielle gÃ©nÃ©ratives suscitent de
   nombreuses craintes et interrogations, tant le contenu gÃ©nÃ©rÃ© est
   saisissant de rÃ©alisme. Sâ€™il devient encore plus difficile de
   distinguer le vrai du faux, la dÃ©sinformation ne risque-t-elle pas de
   se propager encore plus largement ? On peut imaginer la prolifÃ©ration
   de vidÃ©os mettant en scÃ¨ne un homme politique, un artiste, ou tout
   simplement soi-mÃªme ou un proche, avec un contenu factice, une voix
   similaire Ã  la vraie voix, mais avec des propos, des situations et des
   comportements complÃ¨tement inventÃ©s. Les photos du prÃ©sident Trump en
   Ã©tat dâ€™arrestation, du prÃ©sident Macron en Ã©boueur ou du pape en
   doudoune ont dÃ©jÃ  Ã©tÃ© largement mÃ©diatisÃ©es. Plus sordide : des vidÃ©os
   truquÃ©es apparaissent mettant en scÃ¨ne des personnes, cÃ©lÃ¨bres ou non,
   dans des situations dÃ©gradantes [1]. Ces scÃ©narios, dÃ©jÃ  rÃ©alisables
   avec les technologies existantes, deviendraient ainsi Ã  la portÃ©e de
   tous et pourraient Ãªtre dÃ©ployÃ©es Ã  trÃ¨s grande Ã©chelle.

Un risque de dÃ©sinformation accru ?

   Soulignons en prÃ©alable que le problÃ¨me rencontrÃ© par ceux qui veulent
   propager des fausses informations nâ€™a jamais Ã©tÃ© la crÃ©ation de
   contenu, mais sa diffusion. En ce qui concerne la crÃ©ation de contenu,
   de faÃ§on Ã©vidente, les possibilitÃ©s offertes par les IA gÃ©nÃ©ratives
   peuvent sâ€™avÃ©rer dâ€™une grande efficacitÃ© et il importe de ne pas les
   minimiser. En brouillant la frontiÃ¨re entre le vrai et le faux et en
   permettant la production Ã  une Ã©chelle industrielle de fausses photos,
   de fausses vidÃ©os, les IA gÃ©nÃ©ratives dÃ©mocratisent largement ce qui,
   avant, requÃ©rait une expertise pointue, des logiciels spÃ©cialisÃ©s et
   une main-dâ€™Å“uvre coÃ»teuse.

   Mais il sâ€™agit ensuite de diffuser les Â« informations Â» ainsi obtenues.
   LÃ , lâ€™aide apportÃ©e semble plus limitÃ©e. Certes, les IA gÃ©nÃ©ratives
   permettent dâ€™individualiser les interactions sur les rÃ©seaux sociaux,
   rendant plus performantes les interventions des robots informatiques en
   les faisant apparaÃ®tre plus Â« humaines Â». Elles produisent Ã©galement
   des messages plus crÃ©dibles, plus vraisemblables, qui se diffuseront
   plus facilement. Cependant, le support principal pour diffuser la
   dÃ©sinformation reste Internet et les rÃ©seaux sociaux tels quâ€™ils
   existent dÃ©jÃ .
   Les Tricheurs (dÃ©tail), Valentin de Boulogne (1591-1632)

   Le problÃ¨me ne date pas dâ€™aujourdâ€™hui, comme en atteste, par exemple,
   la proportion de faux comptes ou de doublons sur les rÃ©seaux sociaux
   (sur Facebook, ils sont estimÃ©s Ã  16 %, une partie dâ€™entre eux servant
   au spam et Ã  la dÃ©sinformation [2]) ainsi que toutes les controverses
   relatives Ã  la rÃ©gulation et lâ€™autorÃ©gulation face Ã  des contenus
   problÃ©matiques.

   Par ailleurs, ne lâ€™oublions pas, le succÃ¨s de la dÃ©sinformation dÃ©pend
   Ã©galement des attentes des personnes visÃ©es. Une vidÃ©o truquÃ©e
   rencontrera son public si elle est crÃ©dible aux yeux des personnes
   ciblÃ©es et si elle correspond Ã  leur Ã©tat dâ€™esprit et Ã  leurs
   aspirations.

   La dÃ©sinformation nâ€™a attendu ni Internet ni les rÃ©seaux sociaux pour
   se propager Ã  trÃ¨s grande Ã©chelle. Certaines Â« thÃ©ories du complot Â»^ 1
   ont rencontrÃ© un succÃ¨s planÃ©taire, avec des consÃ©quences dramatiques Ã
   une Ã©poque oÃ¹ les ordinateurs nâ€™existaient pas. On pense par exemple au
   Â« protocole des sages de Sion Â», un texte inventÃ© par la police
   tsariste en 1903 et prÃ©sentÃ© comme Ã©tant la preuve matÃ©rielle dâ€™un
   complot juif visant Ã  dominer le monde. Ce texte a largement alimentÃ©
   les discours antisÃ©mites du XX^e siÃ¨cle [3]. Son succÃ¨s sâ€™explique en
   grande partie par le contexte social : il a Â« rencontrÃ© son public Â»
   dans des populations oÃ¹ lâ€™antisÃ©mitisme Ã©tait dÃ©jÃ  bien prÃ©sent. Dâ€™une
   faÃ§on plus gÃ©nÃ©rale, les rumeurs et lÃ©gendes urbaines ont traversÃ©
   toutes les sociÃ©tÃ©s, et ce, bien avant lâ€™avÃ¨nement dâ€™Internet. Elles se
   sont toujours alimentÃ©es dâ€™un mÃ©lange de faits vÃ©rifiables et de faits
   inventÃ©s pour produire un rÃ©cit plausible qui va rencontrer un public
   Â« concernÃ© Â», objectivement ou subjectivement, par les messages
   vÃ©hiculÃ©s [4].

   Enfin, ajoutons que combattre la dÃ©sinformation par des faits validÃ©s
   suppose que ceux qui la propagent ou qui y sont rÃ©ceptifs sont
   sensibles aux arguments et souhaitent confronter leurs croyances. Ce
   nâ€™est malheureusement pas toujours le cas. Les controverses sur la
   vaccination lors de la crise sanitaire lâ€™illustrent.

   Internet et les rÃ©seaux sociaux ont rÃ©volutionnÃ© le champ de la
   dÃ©sinformation. Ils ont en particulier rendu planÃ©taires des phÃ©nomÃ¨nes
   qui restaient le plus souvent locaux. De plus, la vitesse de
   propagation des fausses informations sâ€™est radicalement accrue. Dans ce
   contexte, les IA gÃ©nÃ©ratives pourront apporter leur contribution, câ€™est
   Ã©vident, mais sans toutefois, Ã  ce stade, bouleverser la situation. Il
   importe cependant dâ€™examiner comment il est possible de se prÃ©munir de
   leurs usages spÃ©cifiques quand ils sont nÃ©fastes.

Se prÃ©munir contre les dangers de la dÃ©sinformation

   Avec leur perfectionnement, les nouvelles technologies dâ€™intelligence
   artificielle rendent plus difficile la dÃ©tection des fausses
   informations quâ€™elles peuvent gÃ©nÃ©rer. Mais inversement, ces mÃªmes
   techniques peuvent fournir par ailleurs des solutions aux problÃ¨mes
   quâ€™elles crÃ©ent. On assiste lÃ  Ã  une sorte de course entre gendarmes et
   voleurs, Ã  lâ€™image de ce que lâ€™on a vu, par exemple, avec le
   dÃ©veloppement dâ€™Internet et de WikipÃ©dia : des outils automatiques ont
   Ã©tÃ© mis au point pour dÃ©tecter les plagiats qui sâ€™Ã©taient multipliÃ©s
   dans le monde Ã©tudiant. Il en a Ã©tÃ© de mÃªme pour les images truquÃ©es Ã
   lâ€™aide de logiciels de retouche : dâ€™autres logiciels permettent de
   repÃ©rer ces trucages.

   InsÃ©rer des filigranes
   On pourrait imaginer lâ€™obligation, pour les dÃ©veloppeurs dâ€™IA
   gÃ©nÃ©ratives, dâ€™insÃ©rer une sorte de filigrane dans leurs productions, Ã
   lâ€™image de ce qui se fait dans les billets de banque. Les filigranes
   (ou tatouages) numÃ©riques ne sont pas des nouveautÃ©s. Pour une image,
   ce pourrait par exemple Ãªtre lâ€™insertion discrÃ¨te de pixels selon une
   rÃ©gularitÃ© prÃ©dÃ©finie qui marquerait la signature du logiciel [5]. Le
   dÃ©fi consiste alors Ã  rendre le filigrane Ã  la fois imperceptible Ã
   lâ€™Å“il, mais Ã©galement robuste aux manipulations dâ€™image frÃ©quemment
   faites par les utilisateurs (recadrage, changement de couleurs,
   modification du contraste, etc.) [6]. Stable Diffusion, un systÃ¨me de
   gÃ©nÃ©ration dâ€™image, incorpore dÃ©jÃ  un tel procÃ©dÃ© [7]. Une piste
   complÃ©mentaire pourrait consister Ã  Â« tatouer Â» les enregistrements
   vidÃ©o authentiques lors de la prise de vue grÃ¢ce Ã  une camÃ©ra
   spÃ©cialisÃ©e [5]. Câ€™est la vÃ©ritable information qui serait alors
   marquÃ©e.

   Pour la gÃ©nÃ©ration de textes, lâ€™ajout de filigranes sâ€™avÃ¨re plus
   difficile Ã  rÃ©aliser. OpenAI, la sociÃ©tÃ© qui commercialise ChatGPT,
   Ã©tudie un tel procÃ©dÃ©. Une des pistes envisagÃ©es consiste Ã  intervenir
   dans la phase de gÃ©nÃ©ration dâ€™un mot : au lieu dâ€™un processus de choix
   alÃ©atoire parmi plusieurs propositions jugÃ©es compatibles, la sÃ©lection
   se ferait en utilisant une fonction spÃ©cifique qui signerait en
   quelques sortes la gÃ©nÃ©ration du texte par la machine [8]. Mais il
   semble quâ€™OpenAI Ã©prouve des difficultÃ©s techniques Ã  implanter un tel
   marquage [9]. Et quelles en seraient la fiabilitÃ© et lâ€™efficacitÃ© ? En
   lâ€™Ã©tat, ces rÃ©flexions restent encore assez thÃ©oriques.

   RÃ©gulation et autorÃ©gulation des fournisseurs de logiciel
   Au niveau europÃ©en, le projet Â« AI Act Â» qui vise Ã  rÃ©glementer le
   dÃ©ploiement de systÃ¨mes dâ€™intelligence artificielle [10] propose que
   les Â« hypertrucages Â», câ€™est-Ã -dire les contenus gÃ©nÃ©rÃ©s qui prÃ©sentent
   Â« une ressemblance avec des personnes, des objets, des lieux ou
   dâ€™autres entitÃ©s ou Ã©vÃ©nements existants et pouvant Ãªtre perÃ§us Ã  tort
   comme authentiques ou vÃ©ridiques Â» soient explicitement marquÃ©s lors de
   leur production comme Ã©tant crÃ©Ã©s artificiellement (obligation dite de
   Â« transparence Â»). La mise en Å“uvre technique peut toutefois, comme
   nous lâ€™avons mentionnÃ©, sâ€™avÃ©rer complexe. Elle suppose, par ailleurs,
   pour limiter les risques de contournement et de dÃ©sactivation des
   fonctions de tatouage par des utilisateurs malveillants, que les
   logiciels restent entiÃ¨rement fermÃ©s, que leur code source ne soit pas
   rendu public. Or lâ€™obligation de transparence en gÃ©nÃ©ral prÃ´nÃ©e par les
   rÃ©gulateurs consiste souvent, Ã  lâ€™inverse, Ã  promouvoir une diffusion
   sous une forme dite Â« open source Â» [11].
   Enseignement de la grammaire, enluminure du maÃ®tre de Fauvel dans
   Lâ€™Image du Monde (XIV^es.) BibliothÃ¨que nationale de France

   Une certaine autorÃ©gulation sâ€™est mise en place. ChatGPT, par exemple,
   refuse de rÃ©pondre Ã  certaines requÃªtes ou accompagne certaines
   rÃ©ponses de mises en garde. Pour illustrer, en 2022, vous pouviez
   demander Ã  ChatGPT de proposer un plan de dÃ©sinformation afin de
   convaincre des parents de ne pas vacciner leurs enfants, en prÃ©cisant
   le public visÃ© (par exemple Â« mÃ¨res californiennes adeptes
   dâ€™alimentation saine Â» [12]). Un plan dÃ©taillÃ©, agrÃ©mentÃ© de rÃ©fÃ©rences
   scientifiques, Ã©tait proposÃ©. Le mÃªme essai rÃ©alisÃ© en juin 2023
   conduit Ã  la rÃ©ponse suivante : Â« Je ne peux pas Ã©laborer un plan de
   dÃ©sinformation visant Ã  tromper les parents ou Ã  propager de fausses
   informations. En tant quâ€™intelligence artificielle, mon objectif est de
   fournir des informations prÃ©cises et fiables basÃ©es sur les
   connaissances disponibles. Â» Le systÃ¨me prÃ©sente ensuite des
   recommandations pour orienter lâ€™utilisateur vers Â« des sources fiables
   et basÃ©es sur des preuves scientifiques Â» rappelant que Â« la
   vaccination est un outil essentiel pour prÃ©venir les maladies
   infectieuses et protÃ©ger la santÃ© de la population, y compris celle des
   enfants Â».

   Cette autorÃ©gulation soulÃ¨ve nÃ©anmoins de nombreuses questions. En
   particulier, selon quels critÃ¨res certains sujets doivent-ils Ãªtre
   bannis ? Et cette rÃ©gulation doit-elle Ãªtre laissÃ©e Ã  lâ€™apprÃ©ciation de
   chacun des acteurs ? Cette question particuliÃ¨re nâ€™est pas rÃ©ellement
   nouvelle : elle se pose rÃ©guliÃ¨rement pour le contrÃ´le de contenu des
   rÃ©seaux sociaux, aujourdâ€™hui rÃ©alisÃ© par les opÃ©rateurs eux-mÃªmes. Ce
   qui est spÃ©cifique, câ€™est quâ€™il sâ€™agit non pas de rÃ©guler le contenu
   produit par les humains participant au rÃ©seau, mais, dâ€™une certaine
   faÃ§on, dâ€™Ã©ditorialiser de faÃ§on automatique les productions faites par
   une machine.

Faire preuve dâ€™esprit critique

   Les nouveaux systÃ¨mes dâ€™IA vont permettre de dÃ©mocratiser lâ€™accÃ¨s Ã  des
   outils de crÃ©ation de contenu pour de trÃ¨s nombreuses finalitÃ©s utiles.
   Mais cette accessibilitÃ© Ã  une contrepartie : ils obligent les
   utilisateurs Ã  renforcer leur esprit critique. Dâ€™une certaine maniÃ¨re,
   on peut estimer que tous les Â« piÃ¨ges Â» que des millions dâ€™utilisateurs
   tendent aux IA pour sâ€™amuser, et dont la presse sâ€™est largement faite
   Ã©cho, tÃ©moignent Ã  leur maniÃ¨re de la volontÃ© de nombre dâ€™entre eux de
   tester les limites des systÃ¨mes, de voir dans quelle mesure
   lâ€™information gÃ©nÃ©rÃ©e est fiable.
   Le Penseur, Stanislas Torrents (1839-1916)

   Les dispositifs techniques comme les tatouages numÃ©riques ne seront
   toujours que des outils dâ€™aide qui ne pourront se substituer Ã  une
   formation des utilisateurs et une adaptation des contextes dâ€™usage de
   ces logiciels [13].

   Dans un monde oÃ¹ la frontiÃ¨re entre le vrai et le faux pourra Ãªtre
   rendue plus floue, lâ€™importance de savoir identifier les sources
   dâ€™information fiables deviendra une exigence incontournable.

   Cette Ã©ducation Ã  lâ€™esprit critique, sans Ãªtre en soi suffisante, est
   probablement nÃ©cessaire pour accompagner lâ€™usage des IA gÃ©nÃ©ratives.
   Câ€™est dâ€™ailleurs ainsi quâ€™est souvent envisagÃ©e lâ€™introduction des
   systÃ¨mes dâ€™IA dans les Ã©tablissements dâ€™enseignement, en encourageant
   Â« lâ€™acquisition de â€œcompÃ©tences prÃ©alablesâ€ Ã  lâ€™Ã©ducation Ã  lâ€™IA,
   telles que les compÃ©tences de base en lecture, en Ã©criture, en calcul,
   en programmation et en technologie numÃ©rique, lâ€™Ã©ducation aux mÃ©dias et
   Ã  lâ€™information, ainsi que les compÃ©tences relatives Ã  la pensÃ©e
   critique et crÃ©ative, au travail en Ã©quipe et Ã  la communication, les
   compÃ©tences socioÃ©motionnelles et les compÃ©tences en matiÃ¨re dâ€™Ã©thique
   de lâ€™IA Â» [14].

   Et câ€™est aussi une des raisons dâ€™Ãªtre de lâ€™Afis et de sa revue Science
   et pseudosciences.
   RÃ©fÃ©rences

   1 | Cagan A, Â« Porno : avec lâ€™IA, lâ€™inquiÃ©tant boom des vidÃ©os
   truquÃ©es Â», Lâ€™Express, 4 mai 2023. Sur lexpress.fr
   2 | Moore M, â€œFake accounts on social media, epistemic uncertainty and
   the need for an independent auditing of accountsâ€, Internet Policy
   Review, 7 fÃ©vrier 2023.
   3 | Krivine JP, Â« ThÃ©ories du complot, conspirationnisme : de quoi
   parle-t-on ? Â», SPS nÂ° 337, juillet 2021. Sur afis.org
   4 | Renard JB, Â« Qui croit aux thÃ©ories complotistes et pourquoi ? Â»,
   SPS nÂ° 337, novembre 2021. Sur afis.org
   5 | â€œWatermaking ChatGPT, DALL-E and other generative AIs could help
   protect against fraud and misinformationâ€, The Conversation, 27 mars
   2023. Sur theconversation.com
   6 | Evsutin O, Dzhanashia K, â€œWatermarking schemes for digital images :
   robustness overviewâ€, Signal Processing : Image Communication, 2022,
   100 :116523. Sur sciencedirect.com
   7 | Steins, â€œStable diffusion : the invisible watermark in generated
   imagesâ€, blog, 28 octobre 2022. Sur medium.com
   8 | Aaronson S,â€œMy AI safety lecture for UT effective altruismâ€, blog
   Shtetl-Optimized. Sur scottaaronson.blog
   9 | Wiggers K, â€œOpenAIâ€™s attempts to watermark AI text hit limitsâ€,
   site TechCrunch, 10 dÃ©cembre 2022. Sur techcrunch.com
   10 | Commission europÃ©enne, Â« Proposition de rÃ¨glement du Parlement
   europÃ©en et du Conseil Ã©tablissant des rÃ¨gles harmonisÃ©es concernant
   lâ€™intelligence artificielle et modifiant certains actes lÃ©gislatifs de
   lâ€™Union Â», 21 avril 2021.
   11 | Spirling A, â€œWhy open-source generative AI models are an ethical
   way forward for scienceâ€, Nature, 18 avril 2023.
   12 | Bubeck S et al., â€œSparks of artificial general intelligence :
   early experiments with GPT-4â€, 13 avril 2023 (prÃ©-publication non
   Ã©valuÃ©e par les pairs). Sur arxiv.org
   13 | Lancaster T, â€œArtificial intelligence, text generation tools and
   ChatGPT- Does digital watermaring offer a solution ?â€, International
   Journal for Educational Integrity, 2023, 19 :10.
   14 | Unesco, Â« Ã‰thique de lâ€™intelligence artificielle Â», novembre 2021.

   ^1 Sur les dÃ©finitions que lâ€™on peut donner aux Â« thÃ©ories du
   complot Â», se reporter au dossier Â« ThÃ©ories du complot,
   conspirationnisme : de quoi parle-t-on ? Â», Science et
   pseudo-sciencesnÂ° 337, juillet 2021.

PubliÃ© dans le nÂ° 345 de la revue
     __________________________________________________________________

Partager cet article

   [partage-facebook.png] [partage-twitter.png] [partage-linkedin.png]
   [partage-mail.png]
     __________________________________________________________________

L' auteur

   portrait de l'auteur de cet article Jean-Paul Krivine

Jean-Paul Krivine

   RÃ©dacteur en chef de la revue Science et pseudo-sciences (depuis 2001).
   PrÃ©sident de lâ€™Afis en 2019 et 2020. (...)
   Plus d'informations
     __________________________________________________________________

Intelligence Artificielle

   Lâ€™intelligence artificielle (IA) suscite curiositÃ©, enthousiasme et
   inquiÃ©tude. Elle est prÃ©sente dans dâ€™innombrables applications, ses
   prouesses font rÃ©guliÃ¨rement la une des journaux. Dans le mÃªme temps,
   des dÃ©clarations mÃ©diatisÃ©es mettent en garde contre des machines qui
   pourraient prendre le pouvoir et menacer la place de lâ€™Homme ou, a
   minima, porter atteinte Ã  certaines de nos libertÃ©s. Les performances
   impressionnantes observÃ©es aujourdâ€™hui sont-elles annonciatrices de
   comportements qui vont vite nous Ã©chapper ?
   Intelligence artificielle

Intelligence artificielle

   Le 16 aoÃ»t 2020
   IA gÃ©nÃ©ratives : une rÃ©volution en cours ?

IA gÃ©nÃ©ratives : une rÃ©volution en cours ?

   Le 17 octobre 2023
   De l'analyse de la langue aux modÃ¨les gÃ©nÃ©ratifs

De lâ€™analyse de la langue aux modÃ¨les gÃ©nÃ©ratifs

   Le 11 octobre 2023
   Les systÃ¨mes d'intelligence artificielle pour la gÃ©nÃ©ration d'images

Les systÃ¨mes dâ€™intelligence artificielle pour la gÃ©nÃ©ration dâ€™images

   Le 5 octobre 2023
   IA gÃ©nÃ©ratives : un risque accru de dÃ©sinformation ?

IA gÃ©nÃ©ratives : un risque accru de dÃ©sinformation ?

   Le 29 septembre 2023
   Intelligence artificielle et controverse sur la fin de l'humanitÃ©

Intelligence artificielle et controverse sur la fin de lâ€™humanitÃ©

   Le 23 septembre 2023

Les articles les plus lus

   Le nuage de Tchernobyl qui s'arrÃªte Ã  la frontiÃ¨re : une fable sans
   cesse rÃ©itÃ©rÃ©e

Le nuage de Tchernobyl qui sâ€™arrÃªte Ã  la frontiÃ¨re : une fable sans cesse
rÃ©itÃ©rÃ©e

   Le 22 mars 2021 - Science et mÃ©dias
   Coronavirus : un nouveau paradoxe pour l'homÃ©opathie

Coronavirus : un nouveau paradoxe pour lâ€™homÃ©opathie

   Le 6 mars 2020 - HomÃ©opathie
   Coronavirus â€“ comment s'informer ?

Coronavirus â€“ comment sâ€™informer ?

   Le 11 mai 2020 - Covid-19
   Iridologie : de la poudre aux yeux

Iridologie : de la poudre aux yeux

   Le 4 avril 2020 - MÃ©decines alternatives
   Savez-vous combien pÃ¨se votre Ã¢me ?

Savez-vous combien pÃ¨se votre Ã¢me ?

   Le 9 dÃ©cembre 2019 - Science et religion
     __________________________________________________________________

Notes de lectures

   Le traitement automatique des langues en question

Le traitement automatique des langues en question

   Marcel Cori
   Des intelligences TRÃˆS artificielles

Des intelligences TRÃˆS artificielles

   Jean-Louis Dessalles
   L'intelligence artificielle

Lâ€™intelligence artificielle

   Nicolas Spatola
   Avec Internet, oÃ¹ allons nous ?

Avec Internet, oÃ¹ allons nous ?

   Serge Soudoplatoff
   L'Intelligence et le calcul

Lâ€™Intelligence et le calcul

   Jean-Paul Delahaye
   Toutes les notes de lecture

     * Qui sommes-nous ?
     * Plan du site
     * Liens favoris
     * Contact
     * Mentions
