   Judge’s Order




   Order
   https://www.nytimes.com/2023/07/05/business/media/disinformation-resear
   chers-judge-restrictions.html

   Advertisement

   Supported by

Disinformation Researchers Fret About Fallout From Judge’s Order

   They said a restriction on government interaction with social media
   companies could impede efforts to curb false claims about vaccines and
   voter fraud.

   An audience in an auditorium listens to Barack Obama speak from behind
   a lectern on a stage.
   A federal judge’s decision specifically named some research
   organizations, including the Stanford Internet Observatory. Former
   President Barack Obama spoke about disinformation at Stanford last
   year.Credit...Jim Wilson/The New York Times

   By [12]Tiffany Hsu and [13]Stuart A. Thompson
   July 5, 2023

   A [14]federal judge’s decision this week to restrict the government’s
   communication with social media platforms could have broad side
   effects, according to researchers and groups that combat hate speech,
   online abuse and disinformation: It could further hamper efforts to
   curb harmful content.

   Alice E. Marwick, a researcher at the University of North Carolina at
   Chapel Hill, was one of several disinformation experts who said on
   Wednesday that the ruling could impede work meant to keep false claims
   about vaccines and voter fraud from spreading.

   The order, she said, followed other efforts, largely from Republicans,
   that are “part of an organized campaign pushing back on the idea of
   disinformation as a whole.”

   Judge Terry A. Doughty granted a preliminary injunction on Tuesday,
   saying the Department of Health and Human Services and the Federal
   Bureau of Investigation, along with other parts of the government, must
   stop corresponding with social media companies for “the purpose of
   urging, encouraging, pressuring or inducing in any manner the removal,
   deletion, suppression or reduction of content containing protected free
   speech.”

   The ruling stemmed from a lawsuit by the attorneys general of Louisiana
   and Missouri, who accused Facebook, Twitter and other social media
   sites of censoring right-leaning content, sometimes in league with the
   government. They and other Republicans cheered the judge’s move, in
   U.S. District Court for the Western District of Louisiana, as a win for
   the First Amendment.

   Several researchers, however, said the government’s work with social
   media companies was not an issue as long as it didn’t coerce them to
   remove content. Instead, they said, the government has historically
   notified companies about potentially dangerous messages, like lies
   about election fraud or misleading information about Covid-19. Most
   misinformation or disinformation that violates social platforms’
   policies is flagged by researchers, nonprofits, or people and software
   at the platforms themselves.

   “That’s the really important distinction here: The government should be
   able to inform social media companies about things that they feel are
   harmful to the public,” said Miriam Metzger, a communication professor
   at the University of California, Santa Barbara, and an affiliate of its
   Center for Information Technology and Society.

   A larger concern, researchers said, is a potential chilling effect. The
   judge’s decision blocked certain government agencies from communicating
   with some research organizations, such as the Stanford Internet
   Observatory and the Election Integrity Partnership, about removing
   social media content. Some of those groups have already been targeted
   in a [15]Republican-led legal campaign against universities and think
   tanks.

   Their peers said such stipulations could dissuade younger scholars from
   pursuing disinformation research and intimidate donors who fund crucial
   grants.

   Bond Benton, an associate communication professor at Montclair State
   University who studies disinformation, described the ruling as “a bit
   of a potential Trojan horse.” It is limited on paper to the
   government’s relationship with social media platforms, he said, but
   carried a message that misinformation qualifies as speech and its
   removal as the suppression of speech.

   “Previously, platforms could simply say we don’t want to host it: ‘No
   shirt, no shoes, no service,’” Dr. Benton said. “This ruling will now
   probably make platforms a little bit more cautious about that.”

   In recent years, platforms have relied more heavily on automated tools
   and algorithms to spot harmful content, limiting the effectiveness of
   complaints from people outside the companies. Academics and
   anti-disinformation organizations often complained that platforms were
   unresponsive to their concerns, said Viktorya Vilk, the director for
   digital safety and free expression at PEN America, a nonprofit that
   supports free expression.

   “Platforms are very good at ignoring civil society organizations and
   our requests for help or requests for information or escalation of
   individual cases,” she said. “They are less comfortable ignoring the
   government.”

   Several disinformation researchers worried that the ruling could give
   cover for social media platforms, some of which have already [16]scaled
   back their efforts to curb misinformation, to be even less vigilant
   before the 2024 election. They said it was unclear how relatively new
   government initiatives that had fielded researchers’ concerns and
   suggestions, such as the White House Task Force to Address Online
   Harassment and Abuse, would fare.

   For Imran Ahmed, the chief executive of the Center for Countering
   Digital Hate, the decision on Tuesday underscored other issues: the
   United States’ “particularly fangless” approach to dangerous content
   compared with places like Australia and the European Union, and the
   need to update [17]rules governing social media platforms’ liability.
   The ruling on Tuesday cited the center as having delivered a
   presentation to the surgeon general’s office about its 2021 report on
   online anti-vaccine activists, “[18]The Disinformation Dozen.”

   “It’s bananas that you can’t show a nipple on the Super Bowl but
   Facebook can still broadcast Nazi propaganda, empower stalkers and
   harassers, undermine public health and facilitate extremism in the
   United States,” Mr. Ahmed said. “This court decision further
   exacerbates that feeling of impunity social media companies operate
   under, despite the fact that they are the primary vector for hate and
   disinformation in society.”

   disinformation. [20]More about Tiffany Hsu

   online information flows. [22]More about Stuart A. Thompson
   A version of this article appears in print on  , Section A, Page 14 of
   the New York edition with the headline: Disinformation Researchers Fret
   About Fallout From Judge’s Order. [23]Order Reprints | [24]Today’s
   Paper | [25]Subscribe

   Advertisement

Site Index

Site Information Navigation




   IFRAME:
   zqo1rYDLgYhmTnSjPqw&gtm_preview=env-130&gtm_cookies_win=x

References

   Visible links:
   1. nyt://article/32be7ad9-26d9-5210-8295-56b3c6c71341
   2. https://www.nytimes.com/svc/oembed/json/?url=https://www.nytimes.com/2023/07/05/business/media/disinformation-researchers-judge-restrictions.html
   3. file:///var/folders/3q/w15676x11fz0pvzjk1wr_qp40000gn/T/L42924-1617TMP.html#site-content
   4. file:///var/folders/3q/w15676x11fz0pvzjk1wr_qp40000gn/T/L42924-1617TMP.html#site-index
   5. https://www.nytimes.com/section/business/media
   6. https://www.nytimes.com/section/todayspaper
   7. file:///section/business/media
   8. file:///var/folders/3q/w15676x11fz0pvzjk1wr_qp40000gn/T/L42924-1617TMP.html#after-top
   9. file:///var/folders/3q/w15676x11fz0pvzjk1wr_qp40000gn/T/L42924-1617TMP.html#after-sponsor
  10. https://www.nytimes.com/by/tiffany-hsu
  11. https://www.nytimes.com/by/stuart-a-thompson
  12. https://www.nytimes.com/by/tiffany-hsu
  13. https://www.nytimes.com/by/stuart-a-thompson
  14. https://www.nytimes.com/2023/07/04/business/federal-judge-biden-social-media.html
  15. https://www.nytimes.com/2023/06/19/technology/gop-disinformation-researchers-2024-election.html
  16. https://www.nytimes.com/2023/02/14/technology/disinformation-moderation-social-media.html
  17. https://www.nytimes.com/2023/05/18/us/politics/supreme-court-google-twitter-230.html
  18. https://counterhate.com/research/the-disinformation-dozen/
  19. https://www.nytimes.com/by/tiffany-hsu
  20. https://www.nytimes.com/by/tiffany-hsu
  21. https://www.nytimes.com/by/stuart-a-thompson
  22. https://www.nytimes.com/by/stuart-a-thompson
  23. https://www.parsintl.com/publication/the-new-york-times/
  24. https://www.nytimes.com/section/todayspaper
  25. https://www.nytimes.com/subscriptions/Multiproduct/lp8HYKU.html?campaignId=48JQY
  26. file:///var/folders/3q/w15676x11fz0pvzjk1wr_qp40000gn/T/L42924-1617TMP.html#after-bottom
  27. https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice
  28. https://www.nytco.com/
  29. https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us
  30. https://help.nytimes.com/hc/en-us/articles/115015727108-Accessibility
  31. https://www.nytco.com/careers/
  32. https://nytmediakit.com/
  33. https://www.tbrandstudio.com/
  34. https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers
  35. https://www.nytimes.com/privacy/privacy-policy
  36. https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service
  37. https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale
  38. file:///sitemap/
  39. https://www.nytimes.com/ca/
  40. https://www.nytimes.com/international/
  41. https://help.nytimes.com/hc/en-us
  42. https://www.nytimes.com/subscription?campaignId=37WXW
  43. file:///privacy/manage-settings/?fides-toggle=true&fides-override=true
  44. https://www.googletagmanager.com/ns.html?id=GTM-P528B3&gtm_auth=tfAzqo1rYDLgYhmTnSjPqw&gtm_preview=env-130&gtm_cookies_win=x

   Hidden links:
  46. file://localhost/
  47. file://localhost/
  48. file://localhost/
